{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some preliminary python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of multivariate Wrapper using a RBF SVC\n",
    "\n",
    "For wrapper, we use a model that is trained on a selected subset and the score function $J$ is the estimated real risk of the predictor. Then, for selecting a subset of features, we can use a recursive exploration of the tree of the possible subsets with various strategies refered to as \"Sequential search\", e.g. sequential forward search, sequential backward search, sequential forward floating search, sequential backward floating search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Breast cancer classification dataset\n",
    "\n",
    "As an example, we will consider the breast cancer classification dataset. This classification dataset has 30 continuous features with 569 samples. We look for the best subset of 3 features. The score function is the real risk, as estimated by a 4-fold cross validation, of a linear SVC.\n",
    "\n",
    "As scikit learn does not contain sequential feature selection algorithms, we will use the mlxtend [1] package.\n",
    "\n",
    "\n",
    "[1] http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selector selected 20 features, which have the indices (0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22), i.e. ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter']\n",
      "Accuracy on the test set : 90.70 %\n",
      "Real risk by cross validation for 3 features : 0.96 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "data  = load_breast_cancer()\n",
    "\n",
    "n_samples = data['data'].shape[0]\n",
    "n_features = data['data'].shape[1]\n",
    "\n",
    "# We split the dataset with 15% as a test, using stratified to ensure the train and test sets\n",
    "# both have approximately the same statistics as the whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], stratify=data['target'], test_size=0.15)\n",
    "\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "# We use Sequential Floating Forward Search\n",
    "selector = SFS(clf, \n",
    "           k_features='best', \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           scoring='accuracy',\n",
    "           cv=4,\n",
    "           n_jobs=-1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Print out which are the selected features\n",
    "selected_indices = selector.k_feature_idx_\n",
    "names_selected_indices = [data['feature_names'][i] for i in selected_indices]\n",
    "print(\"The selector selected {} features, which have the indices {}, i.e. {}\".format(len(selected_indices), selected_indices, names_selected_indices))\n",
    "\n",
    "# We perform the feature selection\n",
    "X_train_red = selector.transform(X_train)\n",
    "\n",
    "# And then train our classifier\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train_red, y_train)\n",
    "\n",
    "# Finally, we estimate the accuracy on the test set\n",
    "y_test_pred = clf.predict(selector.transform(X_test))\n",
    "test_accuracy = 100 * (y_test_pred == y_test).sum() / y_test.size\n",
    "print(\"Accuracy on the test set : {:.2f} %\".format(test_accuracy))\n",
    "\n",
    "\n",
    "# We can also estimate the real risk by cross validating the whole process\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SFS(SVC(kernel='rbf'), \n",
    "                        k_features=3, \n",
    "                        forward=True, \n",
    "                        floating=True, \n",
    "                        scoring='accuracy',\n",
    "                        cv=4,\n",
    "                        n_jobs=-1),\n",
    "                    SVC(kernel='rbf'))\n",
    "scores = cross_val_score(clf, data['data'], data['target'], cv=4)\n",
    "print(\"Real risk by cross validation for 3 features : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real risk by cross validation for 1 features : 0.90 (+/- 0.07)\n",
      "Real risk by cross validation for 2 features : 0.94 (+/- 0.05)\n",
      "Real risk by cross validation for 3 features : 0.95 (+/- 0.04)\n",
      "Real risk by cross validation for 4 features : 0.95 (+/- 0.04)\n",
      "Real risk by cross validation for 5 features : 0.96 (+/- 0.04)\n",
      "Real risk by cross validation for 6 features : 0.96 (+/- 0.05)\n",
      "Real risk by cross validation for 7 features : 0.96 (+/- 0.05)\n",
      "Real risk by cross validation for 8 features : 0.97 (+/- 0.06)\n",
      "Real risk by cross validation for 9 features : 0.96 (+/- 0.04)\n",
      "Real risk by cross validation for 10 features : 0.96 (+/- 0.04)\n",
      "Real risk by cross validation for 11 features : 0.96 (+/- 0.04)\n",
      "Real risk by cross validation for 12 features : 0.96 (+/- 0.05)\n",
      "Real risk by cross validation for 13 features : 0.96 (+/- 0.06)\n",
      "Real risk by cross validation for 14 features : 0.97 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "for i in range(1,15):\n",
    "    clf = make_pipeline(StandardScaler(), \n",
    "                    SFS(SVC(kernel='rbf'), \n",
    "                        k_features=i, \n",
    "                        forward=True, \n",
    "                        floating=True, \n",
    "                        scoring='accuracy',\n",
    "                        cv=4,\n",
    "                        n_jobs=-1),\n",
    "                    SVC(kernel='rbf'))\n",
    "    scores = cross_val_score(clf, data['data'], data['target'], cv=10)\n",
    "    print(\"Real risk by cross validation for {} features : {:.2f} (+/- {:.2f})\" .format(i, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
